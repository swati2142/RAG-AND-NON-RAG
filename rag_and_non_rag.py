# -*- coding: utf-8 -*-
"""RAG-AND-NON-RAG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-tX1KrjQBpGmLmXS4frorrly_K5gvget
"""

!pip install pypdf sentence-transformers faiss-cpu transformers torch
!pip install pymupdf

# ===============================
# IMPORT LIBRARIES
# ===============================
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import sys

# ===============================
# STEP 1: LOAD PDF (ERROR SAFE)
# ===============================
file_path = "2019BurkovTheHundred-pageMachineLearning.pdf"

def load_pdf(path):
    text = ""

    try:
        reader = PdfReader(path, strict=False)  # ‚≠ê handles corrupted PDFs
    except Exception as e:
        print("‚ùå Error opening PDF:", e)
        return text

    for i, page in enumerate(reader.pages):
        try:
            content = page.extract_text()
            if content:
                text += content + "\n"
        except Exception:
            print(f"‚ö†Ô∏è Skipping page {i} (corrupted)")

    return text

print("üìö Loading book...")
book_text = load_pdf(file_path)

if len(book_text) == 0:
    print("‚ùå No text extracted. Check PDF file.")
    sys.exit()

print("‚úÖ Book loaded!")
print("Characters:", len(book_text))


# ===============================
# STEP 2: SPLIT TEXT INTO CHUNKS
# ===============================
def chunk_text(text, chunk_size=220):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

chunks = chunk_text(book_text)
print("‚úÖ Chunks created:", len(chunks))


# ===============================
# STEP 3: CREATE EMBEDDINGS (RAG)
# ===============================
print("üîé Creating embeddings...")
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = embed_model.encode(chunks, show_progress_bar=True)


# ===============================
# STEP 4: STORE IN FAISS
# ===============================
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))
print("‚úÖ FAISS index ready!")


# ===============================
# STEP 5: LOAD GENERATOR MODEL
# ===============================
print("ü§ñ Loading generator model...")
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
print("‚úÖ Generator ready!")


def generate_answer(prompt):
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True)
    outputs = model.generate(**inputs, max_new_tokens=200)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)


# ===============================
# RAG FUNCTION
# ===============================
def ask_rag(question):
    q_embed = embed_model.encode([question])
    distances, indices = index.search(np.array(q_embed), k=3)

    context = " ".join([chunks[i] for i in indices[0]])[:1200]

    prompt = f"""
Answer using ONLY the context below.

Context:
{context}

Question: {question}

Explain clearly in simple words.
"""
    return generate_answer(prompt)


# ===============================
# NON-RAG FUNCTION
# ===============================
def ask_nonrag(question):

    prompt = f"""
You are a machine learning expert and tutor.

Answer the question clearly and in detail.
Explain in simple words.
Give a complete explanation.

Question: {question}

Answer:
"""
    return generate_answer(prompt)


# ===============================
# MAIN LOOP (MODE + Q&A)
# ===============================
while True:

    print("\n==============================")
    print("Choose Mode:")
    print("1 ‚Üí RAG (uses book context)")
    print("2 ‚Üí Non-RAG (model knowledge)")
    print("Type 'quit' to close program")
    print("==============================")

    mode = input("Enter 1 or 2: ").lower()

    if mode == "quit":
        print("üëã Closing program...")
        sys.exit()

    if mode not in ["1", "2"]:
        print("‚ùå Invalid choice. Try again.")
        continue

    if mode == "1":
        print("\n‚úÖ RAG mode selected")
    else:
        print("\n‚úÖ Non-RAG mode selected")

    print("\nAsk questions")
    print("Type 'exit' ‚Üí change mode")
    print("Type 'quit' ‚Üí close program\n")

    while True:
        question = input("Ask: ").lower()

        if question == "exit":
            print("\nüîÑ Returning to mode selection...")
            break

        if question == "quit":
            print("\nüëã Closing program...")
            sys.exit()

        if mode == "1":
            answer = ask_rag(question)
        else:
            answer = ask_nonrag(question)

        print("\nüí° Answer:\n", answer)